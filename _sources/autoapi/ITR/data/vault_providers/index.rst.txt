:py:mod:`ITR.data.vault_providers`
==================================

.. py:module:: ITR.data.vault_providers


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   ITR.data.vault_providers.VaultInstance
   ITR.data.vault_providers.VaultProviderProductionBenchmark
   ITR.data.vault_providers.VaultProviderIntensityBenchmark
   ITR.data.vault_providers.VaultCompanyDataProvider
   ITR.data.vault_providers.DataVaultWarehouse



Functions
~~~~~~~~~

.. autoapisummary::

   ITR.data.vault_providers.dequantify_column
   ITR.data.vault_providers.dequantify_df
   ITR.data.vault_providers.requantify_df
   ITR.data.vault_providers.create_vault_table_from_df
   ITR.data.vault_providers.read_quantified_sql



Attributes
~~~~~~~~~~

.. autoapisummary::

   ITR.data.vault_providers.re_simplify_units_both
   ITR.data.vault_providers.re_simplify_units_one
   ITR.data.vault_providers.logger


.. py:data:: re_simplify_units_both
   :value: ' \\/ (\\w+) \\/ (\\w+) \\* \\1 \\* \\2'

   

.. py:data:: re_simplify_units_one
   :value: ' \\/ (\\w+) \\* \\1'

   

.. py:data:: logger

   

.. py:function:: dequantify_column(df_col: pandas.Series) -> pandas.DataFrame


.. py:function:: dequantify_df(df: pandas.DataFrame) -> pandas.DataFrame


.. py:function:: requantify_df(df: pandas.DataFrame, typemap={}) -> pandas.DataFrame


.. py:class:: VaultInstance(engine: sqlalchemy.Engine, catalog: Optional[str] = '', schema: Optional[str] = '', hive_bucket: Optional[mypy_boto3_s3.service_resource.Bucket] = None, hive_catalog: Optional[str] = None, hive_schema: Optional[str] = None)


   Bases: :py:obj:`abc.ABC`

   Helper class that provides a standard way to create an ABC using
   inheritance.


.. py:function:: create_vault_table_from_df(df: pandas.DataFrame, tablename: str, vault: VaultInstance, verbose=False)

   Create a table in the Data Vault

   :param df: The DataFrame to be written as a table in the Data Vault
   :param schemaname: The schema where the table should be written
   :param tablename: The name of the table in the Data Vault
   :param engine: The SqlAlchemy connection to the Data Vault
   :param hive_bucket: :param hive_catalog: :param hive_schema: Optional paramters.  If given we attempt to use a fast Hive ingestion process.  Otherwise use default (and slow) Trino ingestion.
   :param verbose: If True, log information about actions of the Data Vault as they happen


.. py:function:: read_quantified_sql(sql: str, tablename: Union[str, None], engine: sqlalchemy.Engine, schemaname: Optional[str] = '', index_col: Optional[Union[List[str], str, None]] = None) -> pandas.DataFrame


.. py:class:: VaultProviderProductionBenchmark(vault: VaultInstance, benchmark_name: str, prod_df: pandas.DataFrame = pd.DataFrame(), column_config: Type[ITR.configs.ColumnsConfig] = ColumnsConfig)


   Bases: :py:obj:`ITR.data.data_providers.ProductionBenchmarkDataProvider`

   Production projecton data provider super class.

   This Data Container contains Production data on benchmark level. Data has a regions and sector indices.
   Initialized ProductionBenchmarkDataProvider is required when setting up a data warehouse instance.

   .. py:method:: benchmark_changed(new_projected_production: ITR.data.data_providers.ProductionBenchmarkDataProvider) -> bool


   .. py:method:: _get_projected_production(scope: ITR.interfaces.EScope = EScope.AnyScope) -> pandas.DataFrame

      Converts IProductionBenchmarkScopes into dataframe for a scope
      :param scope: a scope
      :return: a pint[dimensionless] pd.DataFrame


   .. py:method:: get_company_projected_production(company_sector_region_scope: pandas.DataFrame) -> pandas.DataFrame

      get the projected productions for list of companies
      :param company_sector_region_scope: DataFrame with at least the following columns :
      ColumnsConfig.COMPANY_ID, ColumnsConfig.SECTOR, ColumnsConfig.REGION, ColumnsConfig.SCOPE
      :return: DataFrame of projected productions for [base_year through 2050]



.. py:class:: VaultProviderIntensityBenchmark(vault: VaultInstance, benchmark_name: str, ei_df_t: pandas.DataFrame = pd.DataFrame(), benchmark_temperature: ITR.data.osc_units.delta_degC_Quantity = Q_(1.5, 'delta_degC'), benchmark_global_budget: ITR.data.osc_units.EmissionsQuantity = Q_(396, 'Gt CO2e'), is_AFOLU_included: bool = False, production_centric: bool = False, column_config: Type[ITR.configs.ColumnsConfig] = ColumnsConfig, projection_controls: ITR.configs.ProjectionControls = ProjectionControls())


   Bases: :py:obj:`ITR.data.data_providers.IntensityBenchmarkDataProvider`

   Production intensity data provider super class.
   This Data Container contains emission intensity data on benchmark level. Data has a regions and sector indices.
   Initialized IntensityBenchmarkDataProvider is required when setting up a data warehouse instance.

   .. py:method:: get_scopes() -> List[ITR.interfaces.EScope]


   .. py:method:: benchmarks_changed(new_projected_ei: ITR.data.data_providers.IntensityBenchmarkDataProvider) -> bool


   .. py:method:: prod_centric_changed(new_projected_ei: ITR.data.data_providers.IntensityBenchmarkDataProvider) -> bool


   .. py:method:: is_production_centric() -> bool

      returns True if benchmark is "production_centric" (as defined by OECM)


   .. py:method:: _get_intensity_benchmarks(company_sector_region_scope: Optional[pandas.DataFrame] = None, scope_to_calc: Optional[ITR.interfaces.EScope] = None) -> pandas.DataFrame

      Overrides subclass method
      returns dataframe of all EI benchmarks if COMPANY_SECTOR_REGION_SCOPE is None.  Otherwise
      returns a Dataframe with intensity benchmarks per company_id given a region and sector.
      :param company_sector_region_scope: DataFrame indexed by ColumnsConfig.COMPANY_ID
      with at least the following columns: ColumnsConfig.SECTOR, ColumnsConfig.REGION, and ColumnsConfig.SCOPE
      :return: A DataFrame with company and intensity benchmarks; rows are calendar years, columns are company data


   .. py:method:: get_SDA_intensity_benchmarks(company_info_at_base_year: pandas.DataFrame, scope_to_calc: Optional[ITR.interfaces.EScope] = None) -> pandas.DataFrame

      Overrides subclass method
      returns a Dataframe with intensity benchmarks per company_id given a region and sector.
      :param company_info_at_base_year: DataFrame with at least the following columns :
      ColumnsConfig.COMPANY_ID, ColumnsConfig.BASE_EI, ColumnsConfig.SECTOR, ColumnsConfig.REGION, ColumnsConfig.SCOPE
      :return: A DataFrame with company and SDA intensity benchmarks per calendar year per row



.. py:class:: VaultCompanyDataProvider(vault: VaultInstance, company_table: str, template_company_data: Union[ITR.data.template.TemplateProviderCompany, None], column_config: Type[ITR.configs.ColumnsConfig] = ColumnsConfig, projection_controls: ITR.configs.ProjectionControls = ProjectionControls())


   Bases: :py:obj:`ITR.data.base_providers.BaseCompanyDataProvider`

   Data provider skeleton for JSON files parsed by the fastAPI json encoder. This class serves primarily for connecting
   to the ITR tool via API.

   :param companies: A list of ICompanyData objects that each contain fundamental company data
   :param column_config: An optional ColumnsConfig object containing relevant variable names
   :param projection_controls: An optional ProjectionControls object containing projection settings

   .. py:method:: get_company_fundamentals(company_ids: List[str]) -> pandas.DataFrame

      :param company_ids: A list of company IDs
      :return: A pandas DataFrame with company fundamental info per company (company_id is a column)


   .. py:method:: get_company_projected_trajectories(company_ids: List[str], year=None) -> pandas.DataFrame

      :param company_ids: A list of company IDs
      :param year: values for a specific year, or all years if None
      :return: A pandas DataFrame with projected intensity trajectories per company, indexed by company_id and scope


   .. py:method:: sum_over_companies(company_ids: List[str], year: int, factor: str, scope: ITR.interfaces.EScope = EScope.S1S2) -> float


   .. py:method:: compute_portfolio_weights(pa_temp_scores: pandas.Series, year: int, factor: str, scope: ITR.interfaces.EScope = EScope.S1S2) -> pandas.Series

      Portfolio values could be position size, temperature scores, anything that can be multiplied by a factor.

      :param company_ids: A pd.Series of company IDs (ISINs)
      :return: A pd.Series weighted by the factor



.. py:class:: DataVaultWarehouse(vault: VaultInstance, company_data: VaultCompanyDataProvider, benchmark_projected_production: VaultProviderProductionBenchmark, benchmarks_projected_ei: VaultProviderIntensityBenchmark, estimate_missing_data: Optional[Callable[[ITR.data.data_warehouse.DataWarehouse, ITR.interfaces.ICompanyData], None]] = None, itr_prefix: Optional[str] = os.environ.get('ITR_PREFIX', ''))


   Bases: :py:obj:`ITR.data.data_warehouse.DataWarehouse`

   General data provider super class.

   .. py:method:: quant_init(vault: VaultInstance, company_data: Union[VaultCompanyDataProvider, None], itr_prefix: str = os.environ.get('ITR_PREFIX', ''))


   .. py:method:: get_preprocessed_company_data(company_ids: List[str]) -> List[ITR.interfaces.ICompanyAggregates]
      :abstractmethod:

      Get all relevant data for a list of company ids. This method should return a list of ICompanyAggregates
      instances.

      :param company_ids: A list of company IDs (ISINs)
      :return: A list containing the company data and additional precalculated fields


   .. py:method:: get_pa_temp_scores(probability: float, company_ids: List[str], scope: ITR.interfaces.EScope = EScope.S1S2, year: int = 2050) -> pandas.Series



