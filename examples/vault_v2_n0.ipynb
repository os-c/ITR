{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c5c7d5-63e0-47a5-ac4a-bb58beb98995",
   "metadata": {},
   "source": [
    "# Data Vault Demo (Dev -- Full Access)\n",
    "\n",
    "The basic concept of the Data Vault is that when a user authenticates themself, they receive an engine that gives them access to all the data (rows, columns, tables, schema, etc.) for which they are authorized.  Users who can authenticate themselves for multiple roles can use those roles simultaneously.  We are keeping in mind the importance of Data Lineage Management (tracked by issue https://github.com/os-climate/os_c_data_commons/issues/50) but is not treated as part of this particular prototype.\n",
    "\n",
    "The steps of this demo are:\n",
    "\n",
    "1. **Authenticate and acquire SQLAlchemy engine**\n",
    "    1. **Dev engine sees all**\n",
    "    2. Quant engine can do temp scoring but not see fundamental company info\n",
    "    3. User engine can use temp scoring but not see cumulative emissions nor overshoot info\n",
    "2. **With Dev engine, construct Vaults for:**\n",
    "    1. **Fundamental corporate financial information**\n",
    "    2. **Corporate emissions data (base year, historical)**\n",
    "    3. **Corporate target data (start year, end year, target start value, target end value)**\n",
    "    4. **Sector benchmark data (production, CO2e intensity)**\n",
    "3. **Dev Engine: Visualize projected emissions (targets and trajectories) and calculate cumulative emissions**\n",
    "4. Quant Engine: Using calculated cumulative emmisions, visualize per-company trajectory and target temperature scores\n",
    "5. User Engine: Using consensus probability scoring and own portfolio data (ISIN, position value)\n",
    "    1. Calculate publishable per-company temperature alignment score\n",
    "    2. Based on aggregate corporate and portfolio information, produce weighting scores to yield overall portfolio alignment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969b6d53-49d8-47d9-b218-6bdd790a7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using connect string: trino://MichaelTiemannOSC@trino-secure-odh-trino.apps.odh-cl2.apps.os-climate.org:443/osc_datacommons_dev/demo_dv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import osc_ingest_trino as osc\n",
    "import trino\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.testing import assert_array_equal\n",
    "import ITR\n",
    "\n",
    "# from ITR.portfolio_aggregation import PortfolioAggregationMethod\n",
    "# from ITR.temperature_score import TemperatureScore\n",
    "# from ITR.configs import ColumnsConfig, TemperatureScoreConfig\n",
    "# from ITR.data.data_warehouse import DataWarehouse\n",
    "from ITR.data.vault_providers import VaultCompanyDataProvider, VaultProviderProductionBenchmark, \\\n",
    "    VaultProviderIntensityBenchmark, DataVaultWarehouse, requantify_df\n",
    "\n",
    "# from ITR.interfaces import ICompanyData, EScope, ETimeFrames, PortfolioCompany, IEIBenchmarkScopes, \\\n",
    "#     IProductionBenchmarkScopes\n",
    "from ITR.interfaces import EScope, IProductionBenchmarkScopes, IEIBenchmarkScopes\n",
    "\n",
    "from ITR.data.osc_units import ureg, Q_, PA_\n",
    "\n",
    "from pint_pandas import PintArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ab75f1-dc99-422d-b15b-ce043e32fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some standard environment variables from a dot-env file, if it exists.\n",
    "# If no such file can be found, does not fail, and so allows these environment vars to\n",
    "# be populated in some other way\n",
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb4e5e-fb6f-42a1-938e-2a3b430d03eb",
   "metadata": {},
   "source": [
    "### Step 1: Initialize Vault user 'Dev', which has full visibility into corporate financial, production, and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ef60e6-a328-4657-aad3-23d78abcbfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting with engine Engine(trino://MichaelTiemannOSC@trino-secure-odh-trino.apps.odh-cl2.apps.os-climate.org:443/)\n",
      "show tables in demo_dv\n",
      "[('benchmark_ei',), ('benchmark_prod',), ('rmi_benchmark_ei',), ('rmi_benchmark_prod',), ('rmi_company_data',), ('rmi_cumulative_budget_1',), ('rmi_cumulative_emissions',), ('rmi_emissions_data',), ('rmi_overshoot_ratios',), ('rmi_production_data',), ('rmi_target_data',), ('rmi_temperature_scores',), ('rmi_trajectory_data',), ('template_benchmark_ei',), ('template_benchmark_prod',), ('template_company_data',), ('template_cumulative_budget_1',), ('template_cumulative_budgets',), ('template_cumulative_emissions',), ('template_emissions_data',), ('template_overshoot_ratios',), ('template_production_data',), ('template_target_data',), ('template_temperature_scores',), ('template_trajectory_data',)]\n"
     ]
    }
   ],
   "source": [
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "\n",
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'demo_dv'\n",
    "itr_prefix = 'template_'\n",
    "\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': ingest_catalog,\n",
    "    'schema': ingest_schema,\n",
    "}\n",
    "\n",
    "engine_dev = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(engine_dev))\n",
    "qres = osc._do_sql(f\"show tables in {ingest_schema}\", engine_dev, verbose=True)\n",
    "\n",
    "# Check that we have the tables we need\n",
    "required_tables = ['company_data', 'target_data', 'trajectory_data', 'emissions_data']\n",
    "existing_tables = [ q[0] for q in qres ]\n",
    "missing_tables = [ rtable for rtable in required_tables if f\"{itr_prefix}{rtable}\" not in existing_tables ]\n",
    "if missing_tables:\n",
    "    print(f\"Missing tables (itr_prefix = {itr_prefix}): {missing_tables}\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837212ac-6d98-46a2-9a18-c5c026feb84c",
   "metadata": {},
   "source": [
    "### The ITR module provides Vault objects that coordinate the interaction of Dev, Quant, and User roles.\n",
    "\n",
    "The SQLAlchemy engines mediate the actual interaction with the Data Vault."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c9ad5-2cee-4052-8001-cce2c41d9f6d",
   "metadata": {},
   "source": [
    "### Step 2: construct vaults for corporate financial, production, and target information.\n",
    "\n",
    "We also create benchmark data (which is presumed public information).  There's more work to be done to modularly add new benchmarks that automatically become available options to to the ITR tool.\n",
    "\n",
    "In this demo we read ITR benchmark data from JSON files (REST API-friendly).  Such data coming from the notebook filesystem is \"untethered\" data.  The corporate data comes from an existing data pipeline (in this case, the pipeline processing RMI data).  When data comes from the data commons, it is \"tethered\" to the Data Commons.  The Data Vault can only control access to data that goes through the Data Commons via 'engines'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f02443-0f8f-4ee1-aa23-f59a9250615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/opt/miniconda3/envs/pandas_2/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:230: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  return _isna_array(np.asarray(obj), inf_as_na=inf_as_na)\n",
      "EXECUTE IMMEDIATE not available for trino-secure-odh-trino.apps.odh-cl2.apps.os-climate.org:443; defaulting to legacy prepared statements (TrinoUserError(type=USER_ERROR, name=SYNTAX_ERROR, message=\"line 1:19: mismatched input ''SELECT 1''. Expecting: 'USING', <EOF>\", query_id=20230730_202703_04222_65cw7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructed fully qualified table name as: \"demo_dv.template_benchmark_prod\"\n",
      "inserting 2208 records\n",
      "  (2019, 0.0, 'dimensionless', 'Global', 'Steel', 'AnyScope')\n",
      "  (2020, 0.00306, 'dimensionless', 'Global', 'Steel', 'AnyScope')\n",
      "  (2021, 0.00306, 'dimensionless', 'Global', 'Steel', 'AnyScope')\n",
      "  ...\n",
      "  (2050, -0.037, 'dimensionless', 'North America', 'Oil & Gas', 'AnyScope')\n",
      "batch insert result: [(2208,)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/opt/miniconda3/envs/pandas_2/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:230: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  return _isna_array(np.asarray(obj), inf_as_na=inf_as_na)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructed fully qualified table name as: \"demo_dv.template_benchmark_ei\"\n",
      "inserting 5000 records\n",
      "  (2019, 0.574, 'CO2e / Fe', 'Global', 'Steel', 'S1', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2020, 0.54, 'CO2e / Fe', 'Global', 'Steel', 'S1', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2021, 0.509, 'CO2e / Fe', 'Global', 'Steel', 'S1', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  ...\n",
      "  (2026, 2.106, 'CO2e * megametric_ton / CH4 / bcm', 'Global', 'Gas', 'S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "batch insert result: [(5000,)]\n",
      "inserting 5000 records\n",
      "  (2027, 2.099, 'CO2e * megametric_ton / CH4 / bcm', 'Global', 'Gas', 'S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2028, 2.093, 'CO2e * megametric_ton / CH4 / bcm', 'Global', 'Gas', 'S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2029, 2.086, 'CO2e * megametric_ton / CH4 / bcm', 'Global', 'Gas', 'S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  ...\n",
      "  (2034, 14.105, 'CO2e * metric_ton / USD / million', 'Global', 'Construction Buildings', 'S1S2S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "batch insert result: [(5000,)]\n",
      "inserting 1040 records\n",
      "  (2035, 12.452, 'CO2e * metric_ton / USD / million', 'Global', 'Construction Buildings', 'S1S2S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2036, 10.898, 'CO2e * metric_ton / USD / million', 'Global', 'Construction Buildings', 'S1S2S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  (2037, 9.538, 'CO2e * metric_ton / USD / million', 'Global', 'Construction Buildings', 'S1S2S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "  ...\n",
      "  (2050, 56.618, 'CO2e * metric_ton / terajoule', 'North America', 'Oil & Gas', 'S1S2S3', 396, 'CO2 * gigametric_ton', 1.5, 'delta_degree_Celsius')\n",
      "batch insert result: [(1040,)]\n",
      "\n",
      "select C.company_name, C.company_id from demo_dv.template_company_data C left join demo_dv.template_target_data EI on EI.company_id=C.company_id\n",
      "where EI.ei_s1_by_year is NULL and EI.ei_s1s2_by_year is NULL and EI.ei_s1s2s3_by_year is NULL\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 16:28:00,477 - ITR.data.vault_providers - ERROR - Provide either historic emissions data or projections for companies with IDs [('OXY CHEM', 'US6745991058-chem'), ('Synthomer Plc', 'GB0009887422'), ('Covestro AG', 'DE0006062144'), ('OXY OIL AND GAS', 'US6745991058-oil')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('OXY CHEM', 'US6745991058-chem'), ('Synthomer Plc', 'GB0009887422'), ('Covestro AG', 'DE0006062144'), ('OXY OIL AND GAS', 'US6745991058-oil')]\n",
      "\n",
      "create table demo_dv.template_cumulative_emissions with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['scope']\n",
      ") as\n",
      "select C.company_name, C.company_id, 'demo_dv' as source, 'S1S2' as scope, P.year,\n",
      "       sum((ET.ei_s1_by_year+if(is_nan(ET.ei_s2_by_year),0.0,ET.ei_s2_by_year)) * P.production_by_year) over (order by P.year) as cumulative_trajectory,\n",
      "       concat(ET.ei_s1_by_year_units, ' * ', P.production_by_year_units) as cumulative_trajectory_units,\n",
      "       sum((EI.ei_s1_by_year+if(is_nan(EI.ei_s2_by_year),0.0,EI.ei_s2_by_year)) * P.production_by_year) over (order by P.year) as cumulative_target,\n",
      "       concat(EI.ei_s1_by_year_units, ' * ', P.production_by_year_units) as cumulative_target_units\n",
      "from demo_dv.template_company_data C\n",
      "     join demo_dv.template_production_data P on P.company_id=C.company_id\n",
      "     join demo_dv.template_target_data EI on EI.company_id=C.company_id and EI.year=P.year and EI.ei_s1_by_year is not NULL\n",
      "     join demo_dv.template_trajectory_data ET on ET.company_id=C.company_id and ET.year=P.year and ET.ei_s1_by_year is not NULL\n",
      "where P.year>=2020\n",
      "UNION ALL\n",
      "select C.company_name, C.company_id, 'demo_dv' as source, 'S1S2S3' as scope, P.year,\n",
      "       sum((ET.ei_s1_by_year+if(is_nan(ET.ei_s2_by_year),0.0,ET.ei_s2_by_year)+if(is_nan(ET.ei_s3_by_year),0.0,ET.ei_s3_by_year)) * P.production_by_year) over (order by P.year) as cumulative_trajectory,\n",
      "       concat(ET.ei_s1_by_year_units, ' * ', P.production_by_year_units) as cumulative_trajectory_units,\n",
      "       sum((EI.ei_s1_by_year+if(is_nan(EI.ei_s2_by_year),0.0,EI.ei_s2_by_year)+if(is_nan(EI.ei_s3_by_year),0.0,EI.ei_s3_by_year)) * P.production_by_year) over (order by P.year) as cumulative_target,\n",
      "       concat(EI.ei_s1_by_year_units, ' * ', P.production_by_year_units) as cumulative_target_units\n",
      "from demo_dv.template_company_data C\n",
      "     join demo_dv.template_production_data P on P.company_id=C.company_id\n",
      "     join demo_dv.template_target_data EI on EI.company_id=C.company_id and EI.year=P.year and EI.ei_s1_by_year is not NULL\n",
      "     join demo_dv.template_trajectory_data ET on ET.company_id=C.company_id and ET.year=P.year and ET.ei_s1_by_year is not NULL\n",
      "where P.year>=2020\n",
      "\n",
      "[(5778,)]\n",
      "\n",
      "create table demo_dv.template_cumulative_budgets with (\n",
      "    format = 'ORC',\n",
      "    partitioning = array['scope']\n",
      ") as\n",
      "select C.company_name, C.company_id, 'demo_dv' as source, B.scope, P.year,  -- FIXME: should have scenario_name and year released\n",
      "       B.global_budget, B.benchmark_temp,\n",
      "       sum(B.intensity * P.production_by_year) over (order by P.year) as cumulative_budget,\n",
      "       concat(B.intensity_units, ' * ', P.production_by_year_units) as cumulative_budget_units,\n",
      "       (CE_BY.cumulative_trajectory/coalesce(B_BY.intensity * P_BY.production_by_year,0)) * sum(B.intensity * P.production_by_year) over (order by P.year) as cumulative_scaled_budget,\n",
      "       concat(B.intensity_units, ' * ', P.production_by_year_units) as cumulative_scaled_budget_units\n",
      "from demo_dv.template_company_data C\n",
      "     join demo_dv.template_production_data P on P.company_id=C.company_id\n",
      "     join demo_dv.template_benchmark_ei B on P.year=B.year and C.region=B.region and C.sector=B.sector\n",
      "     join demo_dv.template_cumulative_emissions CE_BY on CE_BY.company_id=C.company_id and B.scope=CE_BY.scope and CE_BY.year=2019\n",
      "     join demo_dv.template_production_data P_BY on P_BY.company_id=C.company_id and CE_BY.year=P_BY.year\n",
      "     join demo_dv.template_benchmark_ei B_BY on CE_BY.year=B_BY.year and C.region=B_BY.region and C.sector=B_BY.sector\n",
      "where P.year>=2020\n",
      "\n",
      "[(0,)]\n"
     ]
    }
   ],
   "source": [
    "root = root = os.path.dirname(os.getcwd())\n",
    "benchmark_prod_json = os.path.join(root, \"examples/data\", \"json-units\", \"benchmark_production_OECM.json\")\n",
    "benchmark_EI_json = os.path.join(root, \"examples/data\", \"json-units\", \"benchmark_EI_OECM_S3.json\")\n",
    "\n",
    "# load production benchmarks\n",
    "with open(benchmark_prod_json) as json_file:\n",
    "    parsed_json = json.load(json_file)\n",
    "prod_bms = IProductionBenchmarkScopes.parse_obj(parsed_json)\n",
    "vault_production_bm = VaultProviderProductionBenchmark(engine=engine_dev, benchmark_name=f\"{itr_prefix}benchmark_prod\", production_benchmarks=prod_bms)\n",
    "\n",
    "# load intensity benchmarks\n",
    "with open(benchmark_EI_json) as json_file:\n",
    "    parsed_json = json.load(json_file)\n",
    "ei_bms = IEIBenchmarkScopes.parse_obj(parsed_json)\n",
    "vault_EI_bm = VaultProviderIntensityBenchmark(engine=engine_dev, benchmark_name=f\"{itr_prefix}benchmark_ei\", EI_benchmarks=ei_bms)\n",
    "\n",
    "# load company data\n",
    "# TODO: Pandas reads null data mixed with integers as float64 (np.nan).  This can be fixed post hoc with astype('Int16')\n",
    "vault_company_data = VaultCompanyDataProvider(engine=engine_dev, company_table=f\"{itr_prefix}company_data\")\n",
    "\n",
    "vault_warehouse = DataVaultWarehouse(engine_dev, vault_company_data, vault_production_bm, vault_EI_bm, itr_prefix=itr_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02d0f2-0182-430e-9adf-48319beec507",
   "metadata": {},
   "source": [
    "### Step 3: Visualize Emissions, Targets, and Trajectories\n",
    "\n",
    "SuperSet Dashboard here (not really, not yet, but points to TRINO_USER dashboard, not TRINO_USER1 dashboard): https://superset-secure-odh-superset.apps.odh-cl2.apps.os-climate.org/superset/dashboard/4/?edit=true&native_filters=%28%29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a11af2-fc4f-42a6-9ef4-15a7b379ee66",
   "metadata": {},
   "source": [
    "Plot emissions data.  Others can be plotted by following same pattern.\n",
    "\n",
    "Note that without units, a company that emits 80 t CO2e/t Steel looks like it might emit a lot more than one that emits 10t CO2e/MWh.  With units, it becomes clear that the 80 and the 10 are not comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec935e-3ec1-4b2a-91b5-4649720854c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql_table(f\"{itr_prefix}emissions_data\", engine_dev)\n",
    "sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b78e4-ca3a-4af1-bc4d-f301d4e6b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = requantify_df(sql_df.dropna(), typemap={'co2_s1_by_year':'Mt CO2', 'co2_s2_by_year':'Mt CO2', 'co2_s3_by_year':'Mt CO2'}).convert_dtypes()\n",
    "df = df[df.company_id.ne('US6362744095+Gas Utilities') & df.company_id.ne('US0236081024+Gas Utilities') ]\n",
    "df = df[df.co2_s1_by_year.gt(Q_(10.0, 'Mt CO2e'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515b6a5-bfb8-4dc5-81bd-9fe6389be42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4991076-a5a9-4b1a-b19d-2c1744625f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['company_name', 'year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb7060-61e9-4c7e-8389-557192391f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea8112-ecb4-4ae1-a8ea-9065d4177796",
   "metadata": {},
   "outputs": [],
   "source": [
    "ureg.setup_matplotlib(True)\n",
    "plottable_df = df.pivot(index='year', columns='company_name', values='co2_s1_by_year').reset_index()\n",
    "# Must plot the first few columns, but then plot 1/3rd of the companies so as not to over-clutter the graph\n",
    "plottable_df.plot(x='year', kind='line', figsize=(24,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7e2c0-42b8-46e0-8b8d-fb79c8e786d4",
   "metadata": {},
   "source": [
    "## From this point forward, this is just a sketch...\n",
    "\n",
    "While we could technically instantiate Quant and User engines and demonstrate the access restrictions particular to those personna, it's not really \"right\" to demonstrate restrictions via the database that can still be accessed via the python namespace.  So we actually put the following code into separate notebooks which cannot access the data in dataframes above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848722a-342e-46bd-b8fe-aa0001d4d28c",
   "metadata": {},
   "source": [
    "### Step 4: Use Quant engine to access and visualize temperature scores\n",
    "\n",
    "When the Data Vault is ready to be implemented, we can demonstrate that the Quant engine does not have access to primary company data (neither financial nor production)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8110deb5-6850-4f16-902b-c9bab9d338a3",
   "metadata": {},
   "source": [
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER_USER2'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD_USER2']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': 'osc_datacommons_dev',\n",
    "    'schema': 'demo_dv',\n",
    "}\n",
    "\n",
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'demo_dv'\n",
    "\n",
    "engine_quant = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(engine_quant))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12482310-25de-42eb-8d0c-52f56d07f627",
   "metadata": {},
   "source": [
    "Show that we *cannot* access fundamental company data (cannot show until op1st team changes permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c94f8-1709-4d7a-9beb-85419e65be5c",
   "metadata": {},
   "source": [
    "Show that we *can* access both cumulative emissions (input) and temperature scores (output)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7cbe50d-6b26-4f9e-a04b-ba915f19c4b0",
   "metadata": {},
   "source": [
    "temp_score_df = pd.read_sql_table(f\"{itr_prefix}temperature_scores\", engine_quant)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac6a2286-62b7-4d23-81bf-077ad68a34a4",
   "metadata": {},
   "source": [
    "temp_score_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8277b6d5-3633-40ac-b69b-571eae476d99",
   "metadata": {},
   "source": [
    "plottable_df = temp_score_df[['company_name', 'trajectory_temperature_score', 'target_temperature_score']].sort_values('company_name').set_index('company_name').T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acb3b22f-41d8-41a9-a2b0-3a3f0d2ef51a",
   "metadata": {},
   "source": [
    "plottable_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49a139bd-fe5d-4016-87c1-de8fa7c3413a",
   "metadata": {},
   "source": [
    "# Must plot the first few columns, but then plot 1/3rd of the companies so as not to over-clutter the graph\n",
    "plottable_df.iloc[:, [x for x in list(range(0,2)) + list(range(4,35,3))]].boxplot(figsize=(24,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65795474-1de6-4f40-9086-f7d948ae6c66",
   "metadata": {},
   "source": [
    "### Step 5: Show per-company temperature score and weighted portfolio alignment score\n",
    "\n",
    "Portfolio weighting scores (which ultimately influence portfolio alignment score) include:\n",
    "* WATS (size of portfolio company positions used as weights)\n",
    "* TETS (size of total emissions of portfolio companies used as weights)\n",
    "* Financial fundamental weights:\n",
    "    * Market Cap\n",
    "    * Enterprise Value\n",
    "    * Assets\n",
    "    * Revenues\n",
    "\n",
    "We can pass a list of company IDs to the Data Vault to get back a sum without exposing granular data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1de4b009-e664-49c9-a9bb-6021ec944f04",
   "metadata": {},
   "source": [
    "sqlstring = 'trino://{user}@{host}:{port}/'.format(\n",
    "    user = os.environ['TRINO_USER_USER3'],\n",
    "    host = os.environ['TRINO_HOST'],\n",
    "    port = os.environ['TRINO_PORT']\n",
    ")\n",
    "sqlargs = {\n",
    "    'auth': trino.auth.JWTAuthentication(os.environ['TRINO_PASSWD_USER3']),\n",
    "    'http_scheme': 'https',\n",
    "    'catalog': 'osc_datacommons_dev',\n",
    "    'schema': 'demo_dv',\n",
    "}\n",
    "\n",
    "ingest_catalog = 'osc_datacommons_dev'\n",
    "ingest_schema = 'demo_dv'\n",
    "\n",
    "engine_user = create_engine(sqlstring, connect_args = sqlargs)\n",
    "print(\"connecting with engine \" + str(engine_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07154a44-d648-40e3-a5cf-8364468356de",
   "metadata": {},
   "source": [
    "Show that we *cannot* access fundamental company data (cannot show until op1st team changes permissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df114d27-a6ab-46d9-a942-0e8200c4fcd7",
   "metadata": {},
   "source": [
    "Show that we *can* access both cumulative emissions (input) and temperature scores (output)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66770ed9-3403-4ddf-b585-34d78654909e",
   "metadata": {},
   "source": [
    "portfolio_df = pd.read_csv(\"data/mdt-20220116-portfolio.csv\", encoding=\"iso-8859-1\", sep=';', index_col='company_id')\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9942b-ec81-4eab-9cca-99e92905e24f",
   "metadata": {},
   "source": [
    "### Calculate portfolio alignment temperature score based on WATS\n",
    "\n",
    "We can do this with information exclusive to the user space (and the probability-adjusted temperature scores)\n",
    "\n",
    "Note that companies with no production information (such as TITAL INTERNATIONAL INC and UNIVERSAL STAINLESS & ALLOY PRODUCTS INC will show NaN (Not a Number) as a score."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5882ff18-6094-438c-a307-11a11dcb131a",
   "metadata": {},
   "source": [
    "# PA_SCORE means \"Probability-Adjusted\" Temperature Score\n",
    "portfolio_df['pa_score'] = vault_warehouse.get_pa_temp_scores(probability=0.5, company_ids=portfolio_df.index.values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21079b40-dd5c-4b0a-8baa-d3e37b699d25",
   "metadata": {},
   "source": [
    "portfolio_df[portfolio_df.company_name=='POSCO']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c072bdd-a83f-420b-a126-3d981e2b9f54",
   "metadata": {},
   "source": [
    "weight_for_WATS = portfolio_df['investment_value'].sum()\n",
    "weight_for_WATS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b86c6b92-7e4a-4efa-907e-5617a8adf336",
   "metadata": {},
   "source": [
    "portfolio_df['WATS_weight'] = portfolio_df['pa_score'] * (portfolio_df['investment_value'] / weight_for_WATS)\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "628bb37c-84c2-4dc4-826c-c32cf47d8680",
   "metadata": {},
   "source": [
    "print(f\"Portfolio temperature score based on WATS = {portfolio_df['WATS_weight'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95036586-82cc-4230-8946-eb3f7a07d283",
   "metadata": {},
   "source": [
    "### Calculate portfolio alignment temperature score based on TETS\n",
    "\n",
    "We need to carefully meld portfolio data with corp fundamental data (in this case, emissions)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6add035-f666-4572-98f9-9fe71c72fea6",
   "metadata": {},
   "source": [
    "portfolio_df['TETS_weight'] = vault_company_data.compute_portfolio_weights(portfolio_df['pa_score'], 2019, 'emissions', EScope.S1S2)\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee150189-750c-4d08-a53d-4c9540575c98",
   "metadata": {},
   "source": [
    "print(f\"Portfolio temperature score based on TETS = {portfolio_df['TETS_weight'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74453d3b-2288-4dfd-bb68-978c0cdf5f67",
   "metadata": {},
   "source": [
    "### Calculate portfolio alignment temperature score based on MOTS, EOTS, ECOTS, AOTS, and ROTS\n",
    "\n",
    "* MOTS = market cap weights\n",
    "* EOTS = enterprise value weights\n",
    "* ECOTS = EVIC weights\n",
    "* AOTS = asset weights\n",
    "* ROTS = revenue weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9a0cb22-8ee4-4e3b-b08a-9647cc7f51c7",
   "metadata": {},
   "source": [
    "weighting_dict = {\n",
    "    'MOTS': 'company_market_cap',\n",
    "    'EOTS': 'company_enterprise_value',\n",
    "    'ECOTS': 'company_evic',\n",
    "    'AOTS': 'company_total_assets',\n",
    "    'ROTS': 'company_revenue',\n",
    "}\n",
    "\n",
    "for k, v in weighting_dict.items():\n",
    "    weight_column = f\"{k}_weight\"\n",
    "    portfolio_df[weight_column] = vault_company_data.compute_portfolio_weights(portfolio_df['pa_score'], 2019, v, EScope.S1S2)\n",
    "    print(f\"Portfolio temperature score based on {k} = {portfolio_df[weight_column].sum()}\")\n",
    "\n",
    "portfolio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02416ac3-892e-4de7-b244-fc8311993ee9",
   "metadata": {},
   "source": [
    "### Companies for which we lack production data (and thus cannot chart)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efae39b9-706a-451f-8f0e-29daa0e47fee",
   "metadata": {},
   "source": [
    "portfolio_df[portfolio_df.pa_score.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89184619-312b-4303-85d2-7ae1a3093178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
